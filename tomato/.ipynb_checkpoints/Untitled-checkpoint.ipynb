{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict farm comodity prices using deep learned models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-proccess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n",
      "hello\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline  \n",
    "\n",
    "import matplotlib\n",
    "import pandas as pd\n",
    "from numpy import nan\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from dateutil.parser import parse\n",
    "import arrow\n",
    "import numpy\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_extraction import DictVectorizer as DV\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "import csv\n",
    "from keras.models import Sequential\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw_data  = pd.read_csv(\"data.csv\").drop(\"Commodity_Name\",axis = 1)\n",
    "raw_data = raw_data[raw_data[\"Price\"]>0]\n",
    "raw_data[['date','month','year']] = raw_data['Date'].str.split(\"-\",expand=True)\n",
    "raw_data[\"date\"]= raw_data.apply(lambda row: int(row['date']),axis = 1)\n",
    "raw_data[\"month\"]= raw_data.apply(lambda row: int(row['month']),axis = 1)\n",
    "raw_data[\"year\"]= raw_data.apply(lambda row: int(row['year']),axis = 1)\n",
    "raw_data = raw_data.drop(\"Date\",axis =1)\n",
    "raw_data[\"Centre_Name\"] = raw_data[\"Centre_Name\"].astype('category')\n",
    "raw_data[\"Centre_Name_cat\"] = raw_data[\"Centre_Name\"].cat.codes\n",
    "raw_data.to_csv(\"processed.csv\",quoting=csv.QUOTE_NONNUMERIC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DataScalerx = MinMaxScaler()\n",
    "DataScalery = MinMaxScaler()\n",
    "msk = np.random.rand(len(raw_data)) < 0.8\n",
    "raw_data_train = raw_data[msk]\n",
    "raw_data_test = raw_data[~msk]\n",
    "x = DataScalerx.fit_transform(X=raw_data.drop([\"Centre_Name\",\"Price\"],axis=1),y=raw_data[\"Price\"])\n",
    "y = DataScalery.fit_transform(X=raw_data[\"Price\"].values.reshape(-1, 1)) \n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38146, 4)\n",
      "(38146, 1)\n",
      "(9537, 4)\n",
      "(9537, 1)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Dropout, BatchNormalization, Activation\n",
    "import keras.backend as K\n",
    "def mean_pred(y_true, y_pred):\n",
    "    return K.mean(y_pred - y_true)\n",
    "from keras import losses\n",
    "import keras\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "#input layer\n",
    "model.add(Dense(8, input_shape=x_train[0].shape))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "# hidden layers\n",
    "model.add(Dense(8))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"sigmoid\"))\n",
    "model.add(Dropout(0.4))\n",
    "    \n",
    "model.add(Dense(4))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"sigmoid\"))\n",
    "model.add(Dropout(0.4))\n",
    "    \n",
    "model.add(Dense(2, activation=\"sigmoid\"))\n",
    "    \n",
    "# output layer\n",
    "model.add(Dense(1, activation='linear'))\n",
    "\n",
    "model.compile(loss='mse', optimizer='rmsprop',  metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 36238 samples, validate on 1908 samples\n",
      "Epoch 1/15\n",
      "36238/36238 [==============================] - 14s - loss: 0.0111 - mean_absolute_error: 0.0808 - val_loss: 0.0234 - val_mean_absolute_error: 0.1113\n",
      "Epoch 2/15\n",
      "36238/36238 [==============================] - 12s - loss: 0.0108 - mean_absolute_error: 0.0798 - val_loss: 0.0230 - val_mean_absolute_error: 0.1140\n",
      "Epoch 3/15\n",
      "36238/36238 [==============================] - 15s - loss: 0.0106 - mean_absolute_error: 0.0791 - val_loss: 0.0228 - val_mean_absolute_error: 0.1183\n",
      "Epoch 4/15\n",
      "36238/36238 [==============================] - 14s - loss: 0.0106 - mean_absolute_error: 0.0788 - val_loss: 0.0232 - val_mean_absolute_error: 0.1124\n",
      "Epoch 5/15\n",
      "36238/36238 [==============================] - 15s - loss: 0.0104 - mean_absolute_error: 0.0782 - val_loss: 0.0232 - val_mean_absolute_error: 0.1228\n",
      "Epoch 6/15\n",
      "36238/36238 [==============================] - 14s - loss: 0.0105 - mean_absolute_error: 0.0783 - val_loss: 0.0228 - val_mean_absolute_error: 0.1185\n",
      "Epoch 7/15\n",
      "36238/36238 [==============================] - 15s - loss: 0.0104 - mean_absolute_error: 0.0781 - val_loss: 0.0229 - val_mean_absolute_error: 0.1205\n",
      "Epoch 8/15\n",
      "36238/36238 [==============================] - 14s - loss: 0.0104 - mean_absolute_error: 0.0779 - val_loss: 0.0229 - val_mean_absolute_error: 0.1196\n",
      "Epoch 9/15\n",
      "36238/36238 [==============================] - 14s - loss: 0.0103 - mean_absolute_error: 0.0776 - val_loss: 0.0228 - val_mean_absolute_error: 0.1161\n",
      "Epoch 10/15\n",
      "36238/36238 [==============================] - 14s - loss: 0.0103 - mean_absolute_error: 0.0776 - val_loss: 0.0231 - val_mean_absolute_error: 0.1223\n",
      "Epoch 11/15\n",
      "36238/36238 [==============================] - 15s - loss: 0.0102 - mean_absolute_error: 0.0774 - val_loss: 0.0227 - val_mean_absolute_error: 0.1208\n",
      "Epoch 12/15\n",
      "36238/36238 [==============================] - 13s - loss: 0.0102 - mean_absolute_error: 0.0773 - val_loss: 0.0231 - val_mean_absolute_error: 0.1222\n",
      "Epoch 13/15\n",
      "36238/36238 [==============================] - 14s - loss: 0.0101 - mean_absolute_error: 0.0768 - val_loss: 0.0243 - val_mean_absolute_error: 0.1310\n",
      "Epoch 14/15\n",
      "36238/36238 [==============================] - 14s - loss: 0.0102 - mean_absolute_error: 0.0770 - val_loss: 0.0229 - val_mean_absolute_error: 0.1196\n",
      "Epoch 15/15\n",
      "36238/36238 [==============================] - 12s - loss: 0.0102 - mean_absolute_error: 0.0772 - val_loss: 0.0231 - val_mean_absolute_error: 0.1239\n"
     ]
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=15, batch_size=20,validation_split=0.05)\n",
    "model.save(\"hello.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2446.07397461],\n",
       "       [ 2448.20776367],\n",
       "       [ 2448.72705078],\n",
       "       ..., \n",
       "       [ 1441.97668457],\n",
       "       [ 1707.81994629],\n",
       "       [ 1488.2154541 ]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=keras.models.load_model(\"hello.h5\")\n",
    "y_test_predict = model.predict(x_test)\n",
    "DataScalery.inverse_transform(y_test_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
