{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict farm comodity prices using deep learned models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-proccess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n",
      "hello\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline  \n",
    "\n",
    "import matplotlib\n",
    "import pandas as pd\n",
    "from numpy import nan\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from dateutil.parser import parse\n",
    "import arrow\n",
    "import numpy\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_extraction import DictVectorizer as DV\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "import csv\n",
    "from keras.models import Sequential\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Date Centre_Name  Price\n",
      "0  01-01-09  CHANDIGARH    NaN\n",
      "1  01-01-09       DELHI    NaN\n",
      "2  01-01-09      SHIMLA    NaN\n",
      "3  01-01-09    SRINAGAR    NaN\n",
      "4  01-01-09       JAMMU    NaN\n"
     ]
    }
   ],
   "source": [
    "raw_data  = pd.read_csv(\"data.csv\").drop(\"Commodity_Name\",axis = 1)\n",
    "print(raw_data.head())\n",
    "raw_data = raw_data[raw_data[\"Price\"]>0]\n",
    "raw_data[['date','month','year']] = raw_data['Date'].str.split(\"-\",expand=True)\n",
    "raw_data[\"date\"]= raw_data.apply(lambda row: int(row['date']),axis = 1)\n",
    "raw_data[\"month\"]= raw_data.apply(lambda row: int(row['month']),axis = 1)\n",
    "raw_data[\"year\"]= raw_data.apply(lambda row: int(row['year']),axis = 1)\n",
    "raw_data = raw_data.drop(\"Date\",axis =1)\n",
    "raw_data[\"Centre_Name\"] = raw_data[\"Centre_Name\"].astype('category')\n",
    "raw_data[\"Centre_Name_cat\"] = raw_data[\"Centre_Name\"].cat.codes\n",
    "raw_data.to_csv(\"processed.csv\",quoting=csv.QUOTE_NONNUMERIC)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DataScalerx = MinMaxScaler()\n",
    "DataScalery = MinMaxScaler()\n",
    "msk = np.random.rand(len(raw_data)) < 0.8\n",
    "raw_data_train = raw_data[msk]\n",
    "raw_data_test = raw_data[~msk]\n",
    "x = DataScalerx.fit_transform(X=raw_data.drop([\"Centre_Name\",\"Price\"],axis=1),y=raw_data[\"Price\"])\n",
    "y = DataScalery.fit_transform(X=raw_data[\"Price\"].values.reshape(-1, 1)) \n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38146, 4)\n",
      "(38146, 1)\n",
      "(9537, 4)\n",
      "(9537, 1)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Dropout, BatchNormalization, Activation\n",
    "import keras.backend as K\n",
    "def mean_pred(y_true, y_pred):\n",
    "    return K.mean(y_pred - y_true)\n",
    "from keras import losses\n",
    "import keras\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "#input layer\n",
    "model.add(Dense(8, input_shape=x_train[0].shape))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "# hidden layers\n",
    "model.add(Dense(8))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"sigmoid\"))\n",
    "model.add(Dropout(0.4))\n",
    "    \n",
    "model.add(Dense(4))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"sigmoid\"))\n",
    "model.add(Dropout(0.4))\n",
    "    \n",
    "model.add(Dense(2, activation=\"sigmoid\"))\n",
    "    \n",
    "# output layer\n",
    "model.add(Dense(1, activation='linear'))\n",
    "\n",
    "model.compile(loss='mse', optimizer='rmsprop',  metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 36238 samples, validate on 1908 samples\n",
      "Epoch 1/15\n",
      "36238/36238 [==============================] - 14s - loss: 0.0111 - mean_absolute_error: 0.0808 - val_loss: 0.0234 - val_mean_absolute_error: 0.1113\n",
      "Epoch 2/15\n",
      "36238/36238 [==============================] - 12s - loss: 0.0108 - mean_absolute_error: 0.0798 - val_loss: 0.0230 - val_mean_absolute_error: 0.1140\n",
      "Epoch 3/15\n",
      "36238/36238 [==============================] - 15s - loss: 0.0106 - mean_absolute_error: 0.0791 - val_loss: 0.0228 - val_mean_absolute_error: 0.1183\n",
      "Epoch 4/15\n",
      "36238/36238 [==============================] - 14s - loss: 0.0106 - mean_absolute_error: 0.0788 - val_loss: 0.0232 - val_mean_absolute_error: 0.1124\n",
      "Epoch 5/15\n",
      "36238/36238 [==============================] - 15s - loss: 0.0104 - mean_absolute_error: 0.0782 - val_loss: 0.0232 - val_mean_absolute_error: 0.1228\n",
      "Epoch 6/15\n",
      "36238/36238 [==============================] - 14s - loss: 0.0105 - mean_absolute_error: 0.0783 - val_loss: 0.0228 - val_mean_absolute_error: 0.1185\n",
      "Epoch 7/15\n",
      "36238/36238 [==============================] - 15s - loss: 0.0104 - mean_absolute_error: 0.0781 - val_loss: 0.0229 - val_mean_absolute_error: 0.1205\n",
      "Epoch 8/15\n",
      "36238/36238 [==============================] - 14s - loss: 0.0104 - mean_absolute_error: 0.0779 - val_loss: 0.0229 - val_mean_absolute_error: 0.1196\n",
      "Epoch 9/15\n",
      "36238/36238 [==============================] - 14s - loss: 0.0103 - mean_absolute_error: 0.0776 - val_loss: 0.0228 - val_mean_absolute_error: 0.1161\n",
      "Epoch 10/15\n",
      "36238/36238 [==============================] - 14s - loss: 0.0103 - mean_absolute_error: 0.0776 - val_loss: 0.0231 - val_mean_absolute_error: 0.1223\n",
      "Epoch 11/15\n",
      "36238/36238 [==============================] - 15s - loss: 0.0102 - mean_absolute_error: 0.0774 - val_loss: 0.0227 - val_mean_absolute_error: 0.1208\n",
      "Epoch 12/15\n",
      "36238/36238 [==============================] - 13s - loss: 0.0102 - mean_absolute_error: 0.0773 - val_loss: 0.0231 - val_mean_absolute_error: 0.1222\n",
      "Epoch 13/15\n",
      "36238/36238 [==============================] - 14s - loss: 0.0101 - mean_absolute_error: 0.0768 - val_loss: 0.0243 - val_mean_absolute_error: 0.1310\n",
      "Epoch 14/15\n",
      "36238/36238 [==============================] - 14s - loss: 0.0102 - mean_absolute_error: 0.0770 - val_loss: 0.0229 - val_mean_absolute_error: 0.1196\n",
      "Epoch 15/15\n",
      "36238/36238 [==============================] - 12s - loss: 0.0102 - mean_absolute_error: 0.0772 - val_loss: 0.0231 - val_mean_absolute_error: 0.1239\n"
     ]
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=15, batch_size=20,validation_split=0.05)\n",
    "model.save(\"hello.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2446.07397461],\n",
       "       [ 2448.20776367],\n",
       "       [ 2448.72705078],\n",
       "       ..., \n",
       "       [ 1441.97668457],\n",
       "       [ 1707.81994629],\n",
       "       [ 1488.2154541 ]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=keras.models.load_model(\"hello.h5\")\n",
    "y_test_predict = model.predict(x_test)\n",
    "DataScalery.inverse_transform(y_test_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 36238 samples, validate on 1908 samples\n",
      "Epoch 1/25\n",
      "36238/36238 [==============================] - 14s - loss: 0.0101 - mean_absolute_error: 0.0768 - val_loss: 0.0238 - val_mean_absolute_error: 0.1282\n",
      "Epoch 2/25\n",
      "36238/36238 [==============================] - 13s - loss: 0.0101 - mean_absolute_error: 0.0768 - val_loss: 0.0243 - val_mean_absolute_error: 0.1301\n",
      "Epoch 3/25\n",
      "36238/36238 [==============================] - 15s - loss: 0.0100 - mean_absolute_error: 0.0765 - val_loss: 0.0238 - val_mean_absolute_error: 0.1272\n",
      "Epoch 4/25\n",
      "36238/36238 [==============================] - 13s - loss: 0.0101 - mean_absolute_error: 0.0770 - val_loss: 0.0236 - val_mean_absolute_error: 0.1255\n",
      "Epoch 5/25\n",
      "36238/36238 [==============================] - 13s - loss: 0.0100 - mean_absolute_error: 0.0763 - val_loss: 0.0233 - val_mean_absolute_error: 0.1276\n",
      "Epoch 6/25\n",
      "36238/36238 [==============================] - 13s - loss: 0.0100 - mean_absolute_error: 0.0764 - val_loss: 0.0237 - val_mean_absolute_error: 0.1285\n",
      "Epoch 7/25\n",
      "36238/36238 [==============================] - 14s - loss: 0.0100 - mean_absolute_error: 0.0764 - val_loss: 0.0200 - val_mean_absolute_error: 0.1136\n",
      "Epoch 8/25\n",
      "36238/36238 [==============================] - 14s - loss: 0.0100 - mean_absolute_error: 0.0763 - val_loss: 0.0218 - val_mean_absolute_error: 0.1208\n",
      "Epoch 9/25\n",
      "36238/36238 [==============================] - 13s - loss: 0.0100 - mean_absolute_error: 0.0762 - val_loss: 0.0230 - val_mean_absolute_error: 0.1273\n",
      "Epoch 10/25\n",
      "36238/36238 [==============================] - 13s - loss: 0.0100 - mean_absolute_error: 0.0764 - val_loss: 0.0231 - val_mean_absolute_error: 0.1258\n",
      "Epoch 11/25\n",
      "36238/36238 [==============================] - 13s - loss: 0.0100 - mean_absolute_error: 0.0762 - val_loss: 0.0225 - val_mean_absolute_error: 0.1222\n",
      "Epoch 12/25\n",
      "36238/36238 [==============================] - 13s - loss: 0.0100 - mean_absolute_error: 0.0762 - val_loss: 0.0195 - val_mean_absolute_error: 0.1091\n",
      "Epoch 13/25\n",
      "36238/36238 [==============================] - 13s - loss: 0.0100 - mean_absolute_error: 0.0763 - val_loss: 0.0211 - val_mean_absolute_error: 0.1186\n",
      "Epoch 14/25\n",
      "36238/36238 [==============================] - 13s - loss: 0.0101 - mean_absolute_error: 0.0765 - val_loss: 0.0226 - val_mean_absolute_error: 0.1252\n",
      "Epoch 15/25\n",
      "36238/36238 [==============================] - 15s - loss: 0.0099 - mean_absolute_error: 0.0760 - val_loss: 0.0221 - val_mean_absolute_error: 0.1203\n",
      "Epoch 16/25\n",
      "36238/36238 [==============================] - 13s - loss: 0.0100 - mean_absolute_error: 0.0764 - val_loss: 0.0216 - val_mean_absolute_error: 0.1184\n",
      "Epoch 17/25\n",
      "36238/36238 [==============================] - 13s - loss: 0.0100 - mean_absolute_error: 0.0762 - val_loss: 0.0169 - val_mean_absolute_error: 0.0967\n",
      "Epoch 18/25\n",
      "36238/36238 [==============================] - 13s - loss: 0.0101 - mean_absolute_error: 0.0764 - val_loss: 0.0204 - val_mean_absolute_error: 0.1171\n",
      "Epoch 19/25\n",
      "36238/36238 [==============================] - 12s - loss: 0.0101 - mean_absolute_error: 0.0765 - val_loss: 0.0200 - val_mean_absolute_error: 0.1093\n",
      "Epoch 20/25\n",
      "36238/36238 [==============================] - 12s - loss: 0.0100 - mean_absolute_error: 0.0762 - val_loss: 0.0223 - val_mean_absolute_error: 0.1234\n",
      "Epoch 21/25\n",
      "36238/36238 [==============================] - 13s - loss: 0.0100 - mean_absolute_error: 0.0763 - val_loss: 0.0185 - val_mean_absolute_error: 0.1046\n",
      "Epoch 22/25\n",
      "36238/36238 [==============================] - 12s - loss: 0.0100 - mean_absolute_error: 0.0763 - val_loss: 0.0188 - val_mean_absolute_error: 0.1037\n",
      "Epoch 23/25\n",
      "36238/36238 [==============================] - 12s - loss: 0.0100 - mean_absolute_error: 0.0763 - val_loss: 0.0203 - val_mean_absolute_error: 0.1136\n",
      "Epoch 24/25\n",
      "36238/36238 [==============================] - 12s - loss: 0.0099 - mean_absolute_error: 0.0760 - val_loss: 0.0201 - val_mean_absolute_error: 0.1140\n",
      "Epoch 25/25\n",
      "36238/36238 [==============================] - 13s - loss: 0.0100 - mean_absolute_error: 0.0762 - val_loss: 0.0177 - val_mean_absolute_error: 0.1035\n"
     ]
    }
   ],
   "source": [
    "model2 = model\n",
    "model2.fit(x_train, y_train, epochs=25, batch_size=20,validation_split=0.05)\n",
    "model2.save(\"hello.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2751.37353516],\n",
       "       [ 2764.99267578],\n",
       "       [ 2770.78149414],\n",
       "       ..., \n",
       "       [ 1392.90002441],\n",
       "       [ 1395.84716797],\n",
       "       [ 1393.45166016]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3=keras.models.load_model(\"hello.h5\")\n",
    "y_test_predict = model3.predict(x_test)\n",
    "DataScalery.inverse_transform(y_test_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 36238 samples, validate on 1908 samples\n",
      "Epoch 1/100\n",
      "36238/36238 [==============================] - 14s - loss: 0.0099 - mean_absolute_error: 0.0758 - val_loss: 0.0208 - val_mean_absolute_error: 0.1146\n",
      "Epoch 2/100\n",
      "36238/36238 [==============================] - 13s - loss: 0.0100 - mean_absolute_error: 0.0762 - val_loss: 0.0248 - val_mean_absolute_error: 0.1337\n",
      "Epoch 3/100\n",
      "36238/36238 [==============================] - 13s - loss: 0.0100 - mean_absolute_error: 0.0760 - val_loss: 0.0203 - val_mean_absolute_error: 0.1107\n",
      "Epoch 4/100\n",
      "36238/36238 [==============================] - 14s - loss: 0.0099 - mean_absolute_error: 0.0757 - val_loss: 0.0210 - val_mean_absolute_error: 0.1137\n",
      "Epoch 5/100\n",
      "36238/36238 [==============================] - 15s - loss: 0.0098 - mean_absolute_error: 0.0756 - val_loss: 0.0192 - val_mean_absolute_error: 0.1067\n",
      "Epoch 6/100\n",
      "36238/36238 [==============================] - 13s - loss: 0.0099 - mean_absolute_error: 0.0760 - val_loss: 0.0220 - val_mean_absolute_error: 0.1212\n",
      "Epoch 7/100\n",
      "36238/36238 [==============================] - 14s - loss: 0.0099 - mean_absolute_error: 0.0760 - val_loss: 0.0165 - val_mean_absolute_error: 0.0912\n",
      "Epoch 8/100\n",
      "36238/36238 [==============================] - 15s - loss: 0.0098 - mean_absolute_error: 0.0756 - val_loss: 0.0175 - val_mean_absolute_error: 0.1007\n",
      "Epoch 9/100\n",
      "36238/36238 [==============================] - 13s - loss: 0.0099 - mean_absolute_error: 0.0757 - val_loss: 0.0193 - val_mean_absolute_error: 0.1091\n",
      "Epoch 10/100\n",
      "36238/36238 [==============================] - 13s - loss: 0.0098 - mean_absolute_error: 0.0757 - val_loss: 0.0169 - val_mean_absolute_error: 0.0965\n",
      "Epoch 11/100\n",
      "36238/36238 [==============================] - 12s - loss: 0.0100 - mean_absolute_error: 0.0760 - val_loss: 0.0179 - val_mean_absolute_error: 0.1021\n",
      "Epoch 12/100\n",
      "36238/36238 [==============================] - 11s - loss: 0.0100 - mean_absolute_error: 0.0761 - val_loss: 0.0192 - val_mean_absolute_error: 0.1040\n",
      "Epoch 13/100\n",
      "36238/36238 [==============================] - 11s - loss: 0.0099 - mean_absolute_error: 0.0760 - val_loss: 0.0193 - val_mean_absolute_error: 0.1052\n",
      "Epoch 14/100\n",
      "36238/36238 [==============================] - 12s - loss: 0.0100 - mean_absolute_error: 0.0758 - val_loss: 0.0199 - val_mean_absolute_error: 0.1100\n",
      "Epoch 15/100\n",
      "36238/36238 [==============================] - 12s - loss: 0.0099 - mean_absolute_error: 0.0759 - val_loss: 0.0231 - val_mean_absolute_error: 0.1269\n",
      "Epoch 16/100\n",
      "36238/36238 [==============================] - 12s - loss: 0.0099 - mean_absolute_error: 0.0758 - val_loss: 0.0207 - val_mean_absolute_error: 0.1149\n",
      "Epoch 17/100\n",
      "36238/36238 [==============================] - 13s - loss: 0.0099 - mean_absolute_error: 0.0758 - val_loss: 0.0175 - val_mean_absolute_error: 0.0963\n",
      "Epoch 18/100\n",
      "36238/36238 [==============================] - 13s - loss: 0.0100 - mean_absolute_error: 0.0761 - val_loss: 0.0202 - val_mean_absolute_error: 0.1109\n",
      "Epoch 19/100\n",
      "36238/36238 [==============================] - 12s - loss: 0.0099 - mean_absolute_error: 0.0755 - val_loss: 0.0189 - val_mean_absolute_error: 0.1057\n",
      "Epoch 20/100\n",
      "36238/36238 [==============================] - 10s - loss: 0.0099 - mean_absolute_error: 0.0758 - val_loss: 0.0213 - val_mean_absolute_error: 0.1167\n",
      "Epoch 21/100\n",
      "36238/36238 [==============================] - 12s - loss: 0.0099 - mean_absolute_error: 0.0756 - val_loss: 0.0213 - val_mean_absolute_error: 0.1161\n",
      "Epoch 22/100\n",
      "36238/36238 [==============================] - 11s - loss: 0.0100 - mean_absolute_error: 0.0759 - val_loss: 0.0195 - val_mean_absolute_error: 0.1097\n",
      "Epoch 23/100\n",
      "36238/36238 [==============================] - 11s - loss: 0.0099 - mean_absolute_error: 0.0759 - val_loss: 0.0177 - val_mean_absolute_error: 0.0968\n",
      "Epoch 24/100\n",
      "36238/36238 [==============================] - 11s - loss: 0.0099 - mean_absolute_error: 0.0757 - val_loss: 0.0165 - val_mean_absolute_error: 0.0900\n",
      "Epoch 25/100\n",
      "36238/36238 [==============================] - 12s - loss: 0.0099 - mean_absolute_error: 0.0756 - val_loss: 0.0193 - val_mean_absolute_error: 0.1090\n",
      "Epoch 26/100\n",
      "36238/36238 [==============================] - 11s - loss: 0.0098 - mean_absolute_error: 0.0755 - val_loss: 0.0203 - val_mean_absolute_error: 0.1127\n",
      "Epoch 27/100\n",
      "36238/36238 [==============================] - 12s - loss: 0.0098 - mean_absolute_error: 0.0754 - val_loss: 0.0198 - val_mean_absolute_error: 0.1100\n",
      "Epoch 28/100\n",
      "36238/36238 [==============================] - 13s - loss: 0.0099 - mean_absolute_error: 0.0758 - val_loss: 0.0222 - val_mean_absolute_error: 0.1203\n",
      "Epoch 29/100\n",
      "36238/36238 [==============================] - 14s - loss: 0.0099 - mean_absolute_error: 0.0756 - val_loss: 0.0215 - val_mean_absolute_error: 0.1178\n",
      "Epoch 30/100\n",
      "36238/36238 [==============================] - 15s - loss: 0.0099 - mean_absolute_error: 0.0758 - val_loss: 0.0188 - val_mean_absolute_error: 0.1032\n",
      "Epoch 31/100\n",
      "36238/36238 [==============================] - 14s - loss: 0.0099 - mean_absolute_error: 0.0758 - val_loss: 0.0213 - val_mean_absolute_error: 0.1183\n",
      "Epoch 32/100\n",
      "36238/36238 [==============================] - 13s - loss: 0.0099 - mean_absolute_error: 0.0758 - val_loss: 0.0221 - val_mean_absolute_error: 0.1215\n",
      "Epoch 33/100\n",
      "36238/36238 [==============================] - 11s - loss: 0.0099 - mean_absolute_error: 0.0757 - val_loss: 0.0176 - val_mean_absolute_error: 0.0984\n",
      "Epoch 34/100\n",
      "36238/36238 [==============================] - 12s - loss: 0.0099 - mean_absolute_error: 0.0759 - val_loss: 0.0218 - val_mean_absolute_error: 0.1200\n",
      "Epoch 35/100\n",
      "36238/36238 [==============================] - 12s - loss: 0.0099 - mean_absolute_error: 0.0759 - val_loss: 0.0198 - val_mean_absolute_error: 0.1069\n",
      "Epoch 36/100\n",
      "36238/36238 [==============================] - 11s - loss: 0.0098 - mean_absolute_error: 0.0756 - val_loss: 0.0199 - val_mean_absolute_error: 0.1077\n",
      "Epoch 37/100\n",
      "36238/36238 [==============================] - 11s - loss: 0.0099 - mean_absolute_error: 0.0758 - val_loss: 0.0206 - val_mean_absolute_error: 0.1152\n",
      "Epoch 38/100\n",
      "36238/36238 [==============================] - 12s - loss: 0.0098 - mean_absolute_error: 0.0755 - val_loss: 0.0204 - val_mean_absolute_error: 0.1127\n",
      "Epoch 39/100\n",
      "36238/36238 [==============================] - 12s - loss: 0.0099 - mean_absolute_error: 0.0761 - val_loss: 0.0207 - val_mean_absolute_error: 0.1158\n",
      "Epoch 40/100\n",
      "36238/36238 [==============================] - 11s - loss: 0.0099 - mean_absolute_error: 0.0758 - val_loss: 0.0189 - val_mean_absolute_error: 0.1076\n",
      "Epoch 41/100\n",
      "36238/36238 [==============================] - 12s - loss: 0.0099 - mean_absolute_error: 0.0758 - val_loss: 0.0182 - val_mean_absolute_error: 0.0994\n",
      "Epoch 42/100\n",
      "36238/36238 [==============================] - 13s - loss: 0.0098 - mean_absolute_error: 0.0756 - val_loss: 0.0216 - val_mean_absolute_error: 0.1163\n",
      "Epoch 43/100\n",
      "36238/36238 [==============================] - 13s - loss: 0.0099 - mean_absolute_error: 0.0758 - val_loss: 0.0186 - val_mean_absolute_error: 0.1060\n",
      "Epoch 44/100\n",
      "36238/36238 [==============================] - 12s - loss: 0.0099 - mean_absolute_error: 0.0756 - val_loss: 0.0196 - val_mean_absolute_error: 0.1094\n",
      "Epoch 45/100\n",
      "36238/36238 [==============================] - 11s - loss: 0.0099 - mean_absolute_error: 0.0759 - val_loss: 0.0212 - val_mean_absolute_error: 0.1171\n",
      "Epoch 46/100\n",
      "36238/36238 [==============================] - 11s - loss: 0.0099 - mean_absolute_error: 0.0758 - val_loss: 0.0170 - val_mean_absolute_error: 0.0948\n",
      "Epoch 47/100\n",
      "36238/36238 [==============================] - 11s - loss: 0.0099 - mean_absolute_error: 0.0757 - val_loss: 0.0190 - val_mean_absolute_error: 0.1045\n",
      "Epoch 48/100\n",
      "36238/36238 [==============================] - 11s - loss: 0.0099 - mean_absolute_error: 0.0758 - val_loss: 0.0180 - val_mean_absolute_error: 0.0935\n",
      "Epoch 49/100\n",
      "36238/36238 [==============================] - 11s - loss: 0.0098 - mean_absolute_error: 0.0755 - val_loss: 0.0199 - val_mean_absolute_error: 0.1067\n",
      "Epoch 50/100\n",
      "36238/36238 [==============================] - 11s - loss: 0.0098 - mean_absolute_error: 0.0756 - val_loss: 0.0198 - val_mean_absolute_error: 0.1122\n",
      "Epoch 51/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36238/36238 [==============================] - 11s - loss: 0.0098 - mean_absolute_error: 0.0755 - val_loss: 0.0200 - val_mean_absolute_error: 0.1074\n",
      "Epoch 52/100\n",
      "36238/36238 [==============================] - 11s - loss: 0.0098 - mean_absolute_error: 0.0755 - val_loss: 0.0181 - val_mean_absolute_error: 0.1039\n",
      "Epoch 53/100\n",
      "36238/36238 [==============================] - 11s - loss: 0.0098 - mean_absolute_error: 0.0755 - val_loss: 0.0176 - val_mean_absolute_error: 0.0992\n",
      "Epoch 54/100\n",
      "36238/36238 [==============================] - 11s - loss: 0.0099 - mean_absolute_error: 0.0756 - val_loss: 0.0205 - val_mean_absolute_error: 0.1114\n",
      "Epoch 55/100\n",
      "36238/36238 [==============================] - 27s - loss: 0.0099 - mean_absolute_error: 0.0756 - val_loss: 0.0219 - val_mean_absolute_error: 0.1223\n",
      "Epoch 56/100\n",
      "36238/36238 [==============================] - 23s - loss: 0.0099 - mean_absolute_error: 0.0757 - val_loss: 0.0173 - val_mean_absolute_error: 0.0937\n",
      "Epoch 57/100\n",
      "36238/36238 [==============================] - 13s - loss: 0.0100 - mean_absolute_error: 0.0760 - val_loss: 0.0211 - val_mean_absolute_error: 0.1170\n",
      "Epoch 58/100\n",
      "36238/36238 [==============================] - 14s - loss: 0.0099 - mean_absolute_error: 0.0757 - val_loss: 0.0175 - val_mean_absolute_error: 0.0997\n",
      "Epoch 59/100\n",
      "36238/36238 [==============================] - 14s - loss: 0.0099 - mean_absolute_error: 0.0760 - val_loss: 0.0200 - val_mean_absolute_error: 0.1099\n",
      "Epoch 60/100\n",
      "36238/36238 [==============================] - 12s - loss: 0.0099 - mean_absolute_error: 0.0759 - val_loss: 0.0225 - val_mean_absolute_error: 0.1213\n",
      "Epoch 61/100\n",
      "36238/36238 [==============================] - 13s - loss: 0.0099 - mean_absolute_error: 0.0757 - val_loss: 0.0196 - val_mean_absolute_error: 0.1083\n",
      "Epoch 62/100\n",
      "36238/36238 [==============================] - 14s - loss: 0.0099 - mean_absolute_error: 0.0757 - val_loss: 0.0184 - val_mean_absolute_error: 0.0998\n",
      "Epoch 63/100\n",
      "36238/36238 [==============================] - 13s - loss: 0.0099 - mean_absolute_error: 0.0758 - val_loss: 0.0207 - val_mean_absolute_error: 0.1137\n",
      "Epoch 64/100\n",
      "36238/36238 [==============================] - 13s - loss: 0.0098 - mean_absolute_error: 0.0755 - val_loss: 0.0191 - val_mean_absolute_error: 0.1078\n",
      "Epoch 65/100\n",
      "36238/36238 [==============================] - 12s - loss: 0.0100 - mean_absolute_error: 0.0760 - val_loss: 0.0203 - val_mean_absolute_error: 0.1108\n",
      "Epoch 66/100\n",
      "36238/36238 [==============================] - 13s - loss: 0.0099 - mean_absolute_error: 0.0757 - val_loss: 0.0199 - val_mean_absolute_error: 0.1110\n",
      "Epoch 67/100\n",
      "36238/36238 [==============================] - 12s - loss: 0.0099 - mean_absolute_error: 0.0759 - val_loss: 0.0184 - val_mean_absolute_error: 0.1010\n",
      "Epoch 68/100\n",
      "36238/36238 [==============================] - 12s - loss: 0.0099 - mean_absolute_error: 0.0757 - val_loss: 0.0168 - val_mean_absolute_error: 0.0966\n",
      "Epoch 69/100\n",
      "36238/36238 [==============================] - 11s - loss: 0.0099 - mean_absolute_error: 0.0757 - val_loss: 0.0184 - val_mean_absolute_error: 0.1018\n",
      "Epoch 70/100\n",
      "36238/36238 [==============================] - 11s - loss: 0.0098 - mean_absolute_error: 0.0756 - val_loss: 0.0192 - val_mean_absolute_error: 0.1048\n",
      "Epoch 71/100\n",
      "36238/36238 [==============================] - 12s - loss: 0.0099 - mean_absolute_error: 0.0757 - val_loss: 0.0165 - val_mean_absolute_error: 0.0907\n",
      "Epoch 72/100\n",
      "36238/36238 [==============================] - 11s - loss: 0.0098 - mean_absolute_error: 0.0755 - val_loss: 0.0217 - val_mean_absolute_error: 0.1196\n",
      "Epoch 73/100\n",
      "36238/36238 [==============================] - 11s - loss: 0.0099 - mean_absolute_error: 0.0757 - val_loss: 0.0207 - val_mean_absolute_error: 0.1144\n",
      "Epoch 74/100\n",
      "36238/36238 [==============================] - 11s - loss: 0.0099 - mean_absolute_error: 0.0758 - val_loss: 0.0208 - val_mean_absolute_error: 0.1142\n",
      "Epoch 75/100\n",
      "36238/36238 [==============================] - 11s - loss: 0.0099 - mean_absolute_error: 0.0758 - val_loss: 0.0178 - val_mean_absolute_error: 0.0969\n",
      "Epoch 76/100\n",
      "36238/36238 [==============================] - 12s - loss: 0.0099 - mean_absolute_error: 0.0757 - val_loss: 0.0181 - val_mean_absolute_error: 0.1006\n",
      "Epoch 77/100\n",
      "36238/36238 [==============================] - 11s - loss: 0.0099 - mean_absolute_error: 0.0757 - val_loss: 0.0219 - val_mean_absolute_error: 0.1185\n",
      "Epoch 78/100\n",
      "36238/36238 [==============================] - 12s - loss: 0.0099 - mean_absolute_error: 0.0758 - val_loss: 0.0180 - val_mean_absolute_error: 0.0995\n",
      "Epoch 79/100\n",
      "36238/36238 [==============================] - 12s - loss: 0.0099 - mean_absolute_error: 0.0756 - val_loss: 0.0180 - val_mean_absolute_error: 0.0996\n",
      "Epoch 80/100\n",
      "36238/36238 [==============================] - 11s - loss: 0.0099 - mean_absolute_error: 0.0757 - val_loss: 0.0200 - val_mean_absolute_error: 0.1090\n",
      "Epoch 81/100\n",
      "36238/36238 [==============================] - 10s - loss: 0.0098 - mean_absolute_error: 0.0754 - val_loss: 0.0226 - val_mean_absolute_error: 0.1214\n",
      "Epoch 82/100\n",
      "36238/36238 [==============================] - 11s - loss: 0.0100 - mean_absolute_error: 0.0761 - val_loss: 0.0233 - val_mean_absolute_error: 0.1210\n",
      "Epoch 83/100\n",
      "36238/36238 [==============================] - 10s - loss: 0.0099 - mean_absolute_error: 0.0760 - val_loss: 0.0236 - val_mean_absolute_error: 0.1264\n",
      "Epoch 84/100\n",
      "36238/36238 [==============================] - 11s - loss: 0.0099 - mean_absolute_error: 0.0756 - val_loss: 0.0190 - val_mean_absolute_error: 0.1036\n",
      "Epoch 85/100\n",
      "36238/36238 [==============================] - 25s - loss: 0.0099 - mean_absolute_error: 0.0754 - val_loss: 0.0184 - val_mean_absolute_error: 0.1033\n",
      "Epoch 86/100\n",
      "36238/36238 [==============================] - 22s - loss: 0.0099 - mean_absolute_error: 0.0757 - val_loss: 0.0213 - val_mean_absolute_error: 0.1186\n",
      "Epoch 87/100\n",
      "36238/36238 [==============================] - 24s - loss: 0.0099 - mean_absolute_error: 0.0758 - val_loss: 0.0210 - val_mean_absolute_error: 0.1113\n",
      "Epoch 88/100\n",
      "36238/36238 [==============================] - 22s - loss: 0.0099 - mean_absolute_error: 0.0759 - val_loss: 0.0237 - val_mean_absolute_error: 0.1243\n",
      "Epoch 89/100\n",
      "36238/36238 [==============================] - 25s - loss: 0.0099 - mean_absolute_error: 0.0756 - val_loss: 0.0178 - val_mean_absolute_error: 0.0959\n",
      "Epoch 90/100\n",
      "36238/36238 [==============================] - 22s - loss: 0.0099 - mean_absolute_error: 0.0757 - val_loss: 0.0161 - val_mean_absolute_error: 0.0881\n",
      "Epoch 91/100\n",
      "36238/36238 [==============================] - 25s - loss: 0.0098 - mean_absolute_error: 0.0754 - val_loss: 0.0202 - val_mean_absolute_error: 0.1107\n",
      "Epoch 92/100\n",
      "36238/36238 [==============================] - 22s - loss: 0.0099 - mean_absolute_error: 0.0756 - val_loss: 0.0228 - val_mean_absolute_error: 0.1228\n",
      "Epoch 93/100\n",
      "36238/36238 [==============================] - 25s - loss: 0.0099 - mean_absolute_error: 0.0756 - val_loss: 0.0224 - val_mean_absolute_error: 0.1215\n",
      "Epoch 94/100\n",
      "36238/36238 [==============================] - 14s - loss: 0.0099 - mean_absolute_error: 0.0759 - val_loss: 0.0197 - val_mean_absolute_error: 0.1071\n",
      "Epoch 95/100\n",
      "36238/36238 [==============================] - 12s - loss: 0.0099 - mean_absolute_error: 0.0759 - val_loss: 0.0206 - val_mean_absolute_error: 0.1126\n",
      "Epoch 96/100\n",
      "36238/36238 [==============================] - 13s - loss: 0.0099 - mean_absolute_error: 0.0756 - val_loss: 0.0235 - val_mean_absolute_error: 0.1263\n",
      "Epoch 97/100\n",
      "36238/36238 [==============================] - 13s - loss: 0.0099 - mean_absolute_error: 0.0758 - val_loss: 0.0202 - val_mean_absolute_error: 0.1055\n",
      "Epoch 98/100\n",
      "36238/36238 [==============================] - 13s - loss: 0.0098 - mean_absolute_error: 0.0753 - val_loss: 0.0175 - val_mean_absolute_error: 0.0997\n",
      "Epoch 99/100\n",
      "36238/36238 [==============================] - 12s - loss: 0.0099 - mean_absolute_error: 0.0758 - val_loss: 0.0212 - val_mean_absolute_error: 0.1124\n",
      "Epoch 100/100\n",
      "36238/36238 [==============================] - 11s - loss: 0.0099 - mean_absolute_error: 0.0758 - val_loss: 0.0230 - val_mean_absolute_error: 0.1225\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 8)                 40        \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 8)                 32        \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 8)                 32        \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 4)                 36        \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 4)                 16        \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 2)                 10        \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 241\n",
      "Trainable params: 201\n",
      "Non-trainable params: 40\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model4=keras.models.load_model(\"hello.h5\")\n",
    "model4.fit(x_train, y_train, epochs=100, batch_size=20,validation_split=0.05)\n",
    "model4.save(\"hello.h5\")\n",
    "model4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2421.73974609],\n",
       "       [ 2466.98120117],\n",
       "       [ 2504.74633789],\n",
       "       ..., \n",
       "       [ 1432.89038086],\n",
       "       [ 1434.86877441],\n",
       "       [ 1433.60925293]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_predict = model4.predict(x_test)\n",
    "DataScalery.inverse_transform(y_test_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3000.],\n",
       "       [ 7000.],\n",
       "       [ 5000.],\n",
       "       ..., \n",
       "       [ 1700.],\n",
       "       [ 1500.],\n",
       "       [ 1600.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DataScalery.inverse_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model4=keras.models.load_model(\"hello.h5\")\n",
    "model4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.layers.core.Dense at 0x10f5afdd0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x11ec4bdd0>,\n",
       " <keras.layers.core.Activation at 0x11ede5a90>,\n",
       " <keras.layers.core.Dropout at 0x10f5affd0>,\n",
       " <keras.layers.core.Dense at 0x10f5afc90>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x11ee0a9d0>,\n",
       " <keras.layers.core.Activation at 0x11ee7d2d0>,\n",
       " <keras.layers.core.Dropout at 0x11ee69ed0>,\n",
       " <keras.layers.core.Dense at 0x11eee52d0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x11f1369d0>,\n",
       " <keras.layers.core.Activation at 0x11f1c1e90>,\n",
       " <keras.layers.core.Dropout at 0x11f0dec90>,\n",
       " <keras.layers.core.Dense at 0x11f14ebd0>,\n",
       " <keras.layers.core.Dense at 0x11f235f50>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'dense_5/BiasAdd:0' shape=(?, 1) dtype=float32>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4.layers[-1].output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 8)                 40        \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 8)                 32        \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 8)                 32        \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 4)                 36        \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 4)                 16        \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 2)                 10        \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 241\n",
      "Trainable params: 201\n",
      "Non-trainable params: 40\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "testmodel = Sequential(model4.layers)\n",
    "testmodel.summary()\n",
    "# testmodel.compile(loss='mse', optimizer='rmsprop',  metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DataScalery.inverse_transform(testmodel.predict())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
